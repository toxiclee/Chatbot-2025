{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c32b1-f3fe-4697-8c08-62920a548f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "\n",
    "TARGET_CHAR = 500\n",
    "MIN_CHAR = 200\n",
    "MAX_CHAR = 800\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def split_text_into_chunks(md_text: str, pdf_name: str) -> list:\n",
    "    lines = md_text.splitlines()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_char_count = 0\n",
    "    inside_table = False\n",
    "    current_page = 1\n",
    "    buffer = []\n",
    "\n",
    "    def flush_buffer():\n",
    "        nonlocal buffer, current_chunk, current_char_count, current_page\n",
    "        if not buffer:\n",
    "            return\n",
    "        section = \"\\n\".join(buffer).strip()\n",
    "        length = len(section)\n",
    "        if length == 0:\n",
    "            return\n",
    "        if current_char_count + length > MAX_CHAR and current_chunk:\n",
    "            chunks.append({\n",
    "                \"pdf_name\": pdf_name,\n",
    "                \"page_number\": current_page,\n",
    "                \"chunk_text\": \"\\n\".join(current_chunk).strip()\n",
    "            })\n",
    "            current_chunk.clear()\n",
    "            current_char_count = 0\n",
    "        current_chunk.append(section)\n",
    "        current_char_count += length\n",
    "        buffer.clear()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        page_match = re.match(r\"^## Page: (\\d+)\", line)\n",
    "        if page_match:\n",
    "            current_page = int(page_match.group(1))\n",
    "\n",
    "        if re.match(r\"^\\|.*\\|$\", line):\n",
    "            inside_table = True\n",
    "            buffer.append(line)\n",
    "        elif inside_table and (line.startswith(\"|\") or re.match(r\"^[-| ]+$\", line)):\n",
    "            buffer.append(line)\n",
    "        else:\n",
    "            if inside_table:\n",
    "                flush_buffer()\n",
    "                inside_table = False\n",
    "            buffer.append(line)\n",
    "            if re.search(r\"[.!?ã€‚ï¼ï¼Ÿ]$\", line):\n",
    "                flush_buffer()\n",
    "\n",
    "    flush_buffer()\n",
    "    if current_chunk:\n",
    "        chunks.append({\n",
    "            \"pdf_name\": pdf_name,\n",
    "            \"page_number\": current_page,\n",
    "            \"chunk_text\": \"\\n\".join(current_chunk).strip()\n",
    "        })\n",
    "\n",
    "    return [\n",
    "        chunk for chunk in chunks\n",
    "        if len(chunk[\"chunk_text\"]) >= MIN_CHAR\n",
    "    ]\n",
    "\n",
    "def process_md_folder(input_dir, output_dir):\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    md_files = list(input_dir.glob(\"*.md\"))\n",
    "    summary_data = []\n",
    "\n",
    "    print(f\"ğŸ“ å¤„ç† {len(md_files)} ä¸ª Markdown æ–‡ä»¶...\")\n",
    "\n",
    "    for md_file in tqdm(md_files):\n",
    "        text = md_file.read_text(encoding=\"utf-8\")\n",
    "        chunks = split_text_into_chunks(text, md_file.stem + \".pdf\")\n",
    "\n",
    "        csv_rows = []\n",
    "        char_counts = []\n",
    "        token_counts = []\n",
    "\n",
    "        for i, chunk in enumerate(chunks, 1):\n",
    "            chunk_text = chunk[\"chunk_text\"]\n",
    "            char_count = len(chunk_text)\n",
    "            token_count = len(enc.encode(chunk_text))\n",
    "            char_counts.append(char_count)\n",
    "            token_counts.append(token_count)\n",
    "\n",
    "            csv_rows.append({\n",
    "                \"pdf_name\": chunk[\"pdf_name\"],\n",
    "                \"chunk_id\": i,\n",
    "                \"page_number\": chunk[\"page_number\"],\n",
    "                \"character_count\": char_count,\n",
    "                \"token_count\": token_count,\n",
    "                \"content\": chunk_text\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(csv_rows)\n",
    "        df.to_csv(output_dir / f\"{md_file.stem}.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "        summary_data.append({\n",
    "            \"pdf_name\": md_file.name,\n",
    "            \"total_chunks\": len(chunks),\n",
    "            \"total_characters\": sum(char_counts),\n",
    "            \"total_tokens\": sum(token_counts),\n",
    "            \"avg_chars\": np.mean(char_counts) if char_counts else 0,\n",
    "            \"std_chars\": np.std(char_counts) if char_counts else 0,\n",
    "            \"avg_tokens\": np.mean(token_counts) if token_counts else 0,\n",
    "            \"std_tokens\": np.std(token_counts) if token_counts else 0,\n",
    "            \"precision\": None,  # placeholder\n",
    "            \"recall\": None,     # placeholder\n",
    "            \"f1_score\": None    # placeholder\n",
    "        })\n",
    "\n",
    "    # ä¿å­˜æ•´ä½“ summary\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_csv(output_dir / \"chunking_summary.csv\", index=False)\n",
    "\n",
    "    print(f\"âœ… æ‰€æœ‰ chunking å®Œæˆï¼ŒCSV è¾“å‡ºç›®å½•ï¼š{output_dir}\")\n",
    "    print(f\"ğŸ“Š æ±‡æ€»è¡¨æ ¼ï¼š{output_dir/'chunking_summary.csv'}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_md_folder = \"output_md\"                  \n",
    "    output_md_folder = \"Gradient_Chunks_CSV_withpages\"    \n",
    "    process_md_folder(input_md_folder, output_md_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
